# How to Analyse Database SQL slowness using Dynatrace

Leveraging Dynatrace's advanced monitoring capabilities, we can systematically diagnose and resolve the issues affecting database performance. The following steps outline a comprehensive approach to pinpoint and address the root causes of slow database transactions.
Dynatrace provides a dedicated area called **Top Database Statements** for an overview of your database performance, allowing you to identify any immediate anomalies across database calls.

- **Access Top Database Statements**:
**Log into your Dynatrace dashboard, then navigate to Multi-dimensinonal analysis screen**
**Top Database Statements** section. Here, you can view performance metrics that detail how various database statements are performing.
- **Open Multidimensional Analysis**: Clicking on **Top Database Statements** opens a **Multidimensional Analysis** dashboard, providing granular visibility into each database transaction.
![image](https://github.com/user-attachments/assets/cd2718b1-acfb-4bd8-88e6-f144d463dd02)

- **Check for Errors First**: Start by scanning for any failing database statements or requests, as these could indicate a larger issue. If no errors are present, proceed with optimization. It’s reassuring if you find no failed statements since this lets you focus solely on performance improvement without needing to troubleshoot fundamental breakdowns.
- **Locate Slowest Database Transactions**: Investigate further to identify the slowest transaction of the day by focusing on the **outliers**. This will highlight the slowest SQL execution and give your insight into the source of this delay.
**We will search for the following transactions:**
**Check for Errors**: First, investigate any **failing statements** to ensure you’re not dealing with outright database failures. No failed statements? Great! Now you can focus on optimizing.

![image](https://github.com/user-attachments/assets/b91952b7-e875-418e-bd95-3f028a9649c3)

![image](https://github.com/user-attachments/assets/f226be14-cf64-4529-b02b-f13138d7e4b3)

There is no match which means there are no failed database statements. Which is good. o you have failed database statements or failed requests in your environment.

Which is the slowest database transaction of the day? **Continue analysing with the outliers** Detect the slowest execution and understand from where this SQL was triggered.

![image](https://github.com/user-attachments/assets/fc2c3136-3029-4138-8089-daba84d94378)

 **Analyze the Outliers**: Use the Multidimensional Analysis to locate the **slowest SQL statements**. Sort by **response time** and **maximum values** to bring the most time-consuming transactions to the top.
- **Filter and Focus**: Apply filters, such as > response time, to isolate the transactions with significant delays. The goal here is to pinpoint the transactions that are noticeably lagging.

We plot by **response time** and **maximum** and we continue filtering by adding an operand for **\> response time**. Then we select the slowest SQL and Click on **Outliers**.
**Here we get an understanding of the distribution of the transactions. Then Click on the ..., we do a **backtrace** to understand who triggered this SQL.**

![image](https://github.com/user-attachments/assets/104c6522-01b6-425f-8f1f-939001cf1e85)

- **Plot by Response Time**: Visualize the transactions to spot outliers. Then, click on the three- dot menu for a **backtrace** to understand the origin of each transaction.
**Trace the Triggering Application and Endpoint: In the backtrace, pinpoint the application (e.g., EasyTravel Angular) and the endpoint (e.g., /easytravel/rest/journeys/\[1-9\]) initiating the transaction. This analysis offers critical insights into specific user actions or workflows that might be causing unexpected loads on the database.**
![image](https://github.com/user-attachments/assets/9c5234c0-95ad-441e-92a0-d50cbe81922f)

- **Identify High Fetch and Row Counts**: Locate SQL statements with the highest fetch and row counts. This indicates the most data-intensive operations, often contributing to slowdowns.
- **Determine Triggering Sources**: Track back to identify which application or user action (e.g., the **AuthenticationService** or a specific API endpoint) is triggering these resource-heavy queries. This analysis will uncover whether load balancing and request distribution are optimized.

**Which SQL hast the most Fetch count and which the most Row count? Where is this transaction coming from? Which application and which user action is triggering this SQL?**

![image](https://github.com/user-attachments/assets/a74ca784-0384-4ec7-93bb-e7f6623702e7)

**On the backtrace we notice that this transaction is being triggered directly from the AuthenticationService. By clicking on each node you get details of those transactions. here we see the different Methods (requests) and its amount that are triggering such an SQL to the Database. You can also check the instances and validate if the loadbalancing is done properly and which instance (container, pod, etc..) did that transaction at a specific time**

![image](https://github.com/user-attachments/assets/a27ce991-3105-4a49-96cf-611c5a454f96)

Using Dynatrace’s step-by-step diagnostics approach, you can efficiently tackle database transaction slowdowns by:

1. Conducting a **Top Database Statements Analysis** to identify performance bottlenecks.
2. Isolating the **slowest transactions** to understand their impact.
3. Utilizing **backtrace tools** to pinpoint the triggering application and endpoint.
4. Analyzing **fetch and row counts** to detect data-heavy operations.
5. Reviewing **instance distribution** for proper load balancing.

Proactively identifying and resolving slow database transactions can significantly improve your application’s performance and user experience.



